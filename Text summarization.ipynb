{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8b2996b9017b8b1a",
   "metadata": {},
   "source": [
    "# COMPSCI 723 - GRAD TERM PROJECT\n",
    "\n",
    "#### Team Members: \n",
    "##### 1. Shivam Jayeshkumar Mehta (sjmehta@uwm.edu)\n",
    "##### 2. Atharva Pradeep Vaishnav (vaishna2@uwm.edu)\n",
    "##### 3. Venkata Kailash Tanniru (vtanniru@uwm.edu)\n",
    "\n",
    "\n",
    "#### Contributions:\n",
    "###### Shivam Jayeshkumar Mehta :\n",
    "> - Dataset creation and Cleaning.\t\n",
    "> - Extractive Summarization Implementation\n",
    "\n",
    "###### Atharva Pradeep Vaishnav:\n",
    "> - Dataset creation and Cleaning.\n",
    "> - Abstractive Summarization Implementation.\n",
    "\n",
    "###### Venkata Kailash Tanniru:\n",
    "> - Dataset Creation and Cleaning.\n",
    "> - Evaluation Metrics Implementation and Comprehensive Evaluation\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80878862176c9cc0",
   "metadata": {},
   "source": [
    "## Importing Libraries"
   ]
  },
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-21T00:28:00.559615Z",
     "start_time": "2024-12-21T00:28:00.525204Z"
    }
   },
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "import json\n",
    "import nltk\n",
    "import bert_score\n",
    "import textstat\n",
    "from nltk.tokenize import sent_tokenize, word_tokenize\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "import networkx as nx\n",
    "from nltk.corpus import stopwords\n",
    "nltk.download('stopwords')\n",
    "stop_words = set(stopwords.words('english'))\n",
    "nltk.download('punkt')\n",
    "import sentencepiece\n",
    "from transformers import T5Tokenizer, T5ForConditionalGeneration\n",
    "from transformers import pipeline\n",
    "from rouge_score import rouge_scorer\n",
    "from bert_score import score\n",
    "import textstat\n",
    "import torch\n"
   ],
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\SHIVAM\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\SHIVAM\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    }
   ],
   "execution_count": 12
  },
  {
   "cell_type": "markdown",
   "id": "adfc3231459f96e3",
   "metadata": {},
   "source": [
    "### Loading the data"
   ]
  },
  {
   "cell_type": "code",
   "id": "100957d3b007a85d",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-21T00:28:00.808491Z",
     "start_time": "2024-12-21T00:28:00.721599Z"
    }
   },
   "source": [
    "json_file_path = 'test_data.json'\n",
    "\n",
    "with open(json_file_path, 'r') as file:\n",
    "    data = json.load(file)\n",
    "\n",
    "df = pd.DataFrame(data)\n",
    "print(\"Data loaded successfully!\")\n",
    "\n",
    "# displaying the input data\n",
    "df.head(100)\n"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data loaded successfully!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "                                             article  \\\n",
       "0  for about 20 years the problem of properties o...   \n",
       "1  it is believed that the direct detection of gr...   \n",
       "2  as a common quantum phenomenon , the tunneling...   \n",
       "3  the short - lived radioisotope ( slri ) @xmath...   \n",
       "4  as in our previous analysis of run 1a data  @x...   \n",
       "5  this review focuses specifically on what we ha...   \n",
       "6  single - transverse spin asymmetries ( ssas ) ...   \n",
       "7  kingman s coalescent is a random tree introduc...   \n",
       "8  circumstellar material holds clues about the m...   \n",
       "\n",
       "                                            abstract  \n",
       "0  The study investigates short-term periodicitie...  \n",
       "1  This study examines the potential to detect ci...  \n",
       "2  A new barrier penetration formula, derived fro...  \n",
       "3  The study explores marginally gravitationally ...  \n",
       "4  CDF searched for new particles decaying into j...  \n",
       "5  Observations of pre-supernova images reveal in...  \n",
       "6  This study explores single-transverse spin asy...  \n",
       "7  Kingmanâ€™s coalescent models genetic ancestri...  \n",
       "8  The study of circumstellar environments around...  "
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>article</th>\n",
       "      <th>abstract</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>for about 20 years the problem of properties o...</td>\n",
       "      <td>The study investigates short-term periodicitie...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>it is believed that the direct detection of gr...</td>\n",
       "      <td>This study examines the potential to detect ci...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>as a common quantum phenomenon , the tunneling...</td>\n",
       "      <td>A new barrier penetration formula, derived fro...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>the short - lived radioisotope ( slri ) @xmath...</td>\n",
       "      <td>The study explores marginally gravitationally ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>as in our previous analysis of run 1a data  @x...</td>\n",
       "      <td>CDF searched for new particles decaying into j...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>this review focuses specifically on what we ha...</td>\n",
       "      <td>Observations of pre-supernova images reveal in...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>single - transverse spin asymmetries ( ssas ) ...</td>\n",
       "      <td>This study explores single-transverse spin asy...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>kingman s coalescent is a random tree introduc...</td>\n",
       "      <td>Kingmanâ€™s coalescent models genetic ancestri...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>circumstellar material holds clues about the m...</td>\n",
       "      <td>The study of circumstellar environments around...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 13
  },
  {
   "cell_type": "markdown",
   "id": "e75a96c7fa800d37",
   "metadata": {},
   "source": [
    "## Text Cleaning"
   ]
  },
  {
   "cell_type": "code",
   "id": "6ce076f8f1271172",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-21T00:28:00.917517Z",
     "start_time": "2024-12-21T00:28:00.904265Z"
    }
   },
   "source": [
    "def clean_text(text):\n",
    "\n",
    "    # removing names prefixed with '@'\n",
    "    text = re.sub(r'@\\w+', '', text)\n",
    "    \n",
    "    # removing placeholders like 'xmath' followed by numbers\n",
    "    text = re.sub(r'\\bxmath\\d+\\b', '', text)\n",
    "    \n",
    "    # removing figure, table, formula, and equation mentions\n",
    "    text = re.sub(r'\\b(fig(?:ure)?\\.?|table|formula|equation)\\s*\\[?\\w*?\\]?\\b', '', text, flags=re.IGNORECASE)\n",
    "    \n",
    "    # removing references and citations.\n",
    "    text = re.sub(r'\\[\\d+\\]', '', text)\n",
    "    text = re.sub(r'\\[@.*?\\]', '', text)\n",
    "    \n",
    "    # removing all math expressions and LaTeX commands\n",
    "    text = re.sub(r'\\$.*?\\$', '', text)                  \n",
    "    text = re.sub(r'\\\\[a-zA-Z]+(\\{.*?\\})?', '', text)    \n",
    "    text = re.sub(r'\\{.*?\\}', '', text)\n",
    "    text = re.sub(r'\\(.*?\\)', '', text)\n",
    "    \n",
    "    # removing URLs and email addresses\n",
    "    text = re.sub(r'https?://\\S+|www\\.\\S+', '', text)\n",
    "    text = re.sub(r'\\S+@\\S+', '', text)\n",
    "    \n",
    "    # removing multiple spaces, newlines, and special characters with a single space\n",
    "    text = re.sub(r'[^a-zA-Z0-9\\s.,;?!]', '', text)\n",
    "    text = re.sub(r'\\s+', ' ', text)\n",
    "    \n",
    "    # Standardizing text to lowercase\n",
    "    text = text.lower()\n",
    "    \n",
    "    # removing duplicate sentences\n",
    "    sentences = list(dict.fromkeys(sent_tokenize(text)))\n",
    "    text = ' '.join(sentences)\n",
    "    \n",
    "    # removing the trailing spaces\n",
    "    text = text.strip()\n",
    "    \n",
    "    return text"
   ],
   "outputs": [],
   "execution_count": 14
  },
  {
   "cell_type": "code",
   "id": "9dac78319a2213bd",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-21T00:28:01.148941Z",
     "start_time": "2024-12-21T00:28:01.028685Z"
    }
   },
   "source": [
    "df['cleaned_article'] = df['article'].apply(clean_text)\n",
    "print(\"\\nText cleaning completed!\")\n",
    "\n",
    "# Display cleaned articles for verification\n",
    "df[['article', 'cleaned_article']].head(100)"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Text cleaning completed!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "                                             article  \\\n",
       "0  for about 20 years the problem of properties o...   \n",
       "1  it is believed that the direct detection of gr...   \n",
       "2  as a common quantum phenomenon , the tunneling...   \n",
       "3  the short - lived radioisotope ( slri ) @xmath...   \n",
       "4  as in our previous analysis of run 1a data  @x...   \n",
       "5  this review focuses specifically on what we ha...   \n",
       "6  single - transverse spin asymmetries ( ssas ) ...   \n",
       "7  kingman s coalescent is a random tree introduc...   \n",
       "8  circumstellar material holds clues about the m...   \n",
       "\n",
       "                                     cleaned_article  \n",
       "0  for about 20 years the problem of properties o...  \n",
       "1  it is believed that the direct detection of gr...  \n",
       "2  as a common quantum phenomenon , the tunneling...  \n",
       "3  the short lived radioisotope was alive during ...  \n",
       "4  as in our previous analysis of run 1a data , w...  \n",
       "5  this review focuses specifically on what we ha...  \n",
       "6  single transverse spin asymmetries play a fund...  \n",
       "7  kingman s coalescent is a random tree introduc...  \n",
       "8  circumstellar material holds clues about the m...  "
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>article</th>\n",
       "      <th>cleaned_article</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>for about 20 years the problem of properties o...</td>\n",
       "      <td>for about 20 years the problem of properties o...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>it is believed that the direct detection of gr...</td>\n",
       "      <td>it is believed that the direct detection of gr...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>as a common quantum phenomenon , the tunneling...</td>\n",
       "      <td>as a common quantum phenomenon , the tunneling...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>the short - lived radioisotope ( slri ) @xmath...</td>\n",
       "      <td>the short lived radioisotope was alive during ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>as in our previous analysis of run 1a data  @x...</td>\n",
       "      <td>as in our previous analysis of run 1a data , w...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>this review focuses specifically on what we ha...</td>\n",
       "      <td>this review focuses specifically on what we ha...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>single - transverse spin asymmetries ( ssas ) ...</td>\n",
       "      <td>single transverse spin asymmetries play a fund...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>kingman s coalescent is a random tree introduc...</td>\n",
       "      <td>kingman s coalescent is a random tree introduc...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>circumstellar material holds clues about the m...</td>\n",
       "      <td>circumstellar material holds clues about the m...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 15
  },
  {
   "cell_type": "markdown",
   "id": "1b034295a5e50d37",
   "metadata": {},
   "source": [
    "## Text Summarization"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dcac44a9800807ad",
   "metadata": {},
   "source": [
    "#### Extractive Summarization - TextRank Algorithm"
   ]
  },
  {
   "cell_type": "code",
   "id": "91bb3b22a11d56c6",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-21T00:28:01.243004Z",
     "start_time": "2024-12-21T00:28:01.229727Z"
    }
   },
   "source": [
    "def text_rank_summary(text, max_words=100, min_words=60):\n",
    "    # Cleaning the input text\n",
    "    cleaned_text = clean_text(text)\n",
    "    \n",
    "    # tokenizing the text into sentences\n",
    "    sentences = sent_tokenize(cleaned_text)\n",
    "    \n",
    "    # ensuring there's content to process\n",
    "    if len(sentences) < 2:\n",
    "        return \"Not enough content to summarize.\"\n",
    "    \n",
    "    # preprocessing sentences by removing stopwords and filtering out very short/long sentences\n",
    "    preprocessed_sentences = []\n",
    "    valid_sentences = []\n",
    "    \n",
    "    for i, sentence in enumerate(sentences):\n",
    "        preprocessed = ' '.join([word for word in word_tokenize(sentence.lower()) if word.isalnum() and word not in stop_words])\n",
    "        if len(preprocessed.split()) >= 5:  # filtering out very short sentences\n",
    "            preprocessed_sentences.append(preprocessed)\n",
    "            valid_sentences.append(sentence)\n",
    "    \n",
    "    # send the error to display If no valid sentences remain after preprocessing\n",
    "    if len(preprocessed_sentences) < 2:\n",
    "        return \"Not enough content to summarize.\"\n",
    "    \n",
    "    # doing TF-IDF vectorization\n",
    "    vectorizer = TfidfVectorizer(ngram_range=(1, 2))\n",
    "    tfidf_matrix = vectorizer.fit_transform(preprocessed_sentences)\n",
    "    \n",
    "    # calculating the cosine similarity between sentences\n",
    "    similarity_matrix = cosine_similarity(tfidf_matrix, tfidf_matrix)\n",
    "    \n",
    "    # building the graph and apply PageRank\n",
    "    nx_graph = nx.from_numpy_array(similarity_matrix)\n",
    "    scores = nx.pagerank(nx_graph)\n",
    "    \n",
    "    # ranking sentences by their scores\n",
    "    ranked_sentences = sorted(((scores[i], valid_sentences[i]) for i in range(len(valid_sentences))), reverse=True)\n",
    "    \n",
    "    # selecting the top sentences until word limit is reached\n",
    "    summary_sentences = []\n",
    "    total_words = 0\n",
    "    \n",
    "    for score, sentence in ranked_sentences:\n",
    "        word_count = len(word_tokenize(sentence))\n",
    "        if total_words + word_count <= max_words:\n",
    "            summary_sentences.append(sentence)\n",
    "            total_words += word_count\n",
    "        if total_words >= min_words:\n",
    "            break\n",
    "    \n",
    "    # sorting sentences by their original position to improve coherence and readability\n",
    "    summary_sentences.sort(key=lambda s: sentences.index(s))\n",
    "    \n",
    "    # Join the sentences to form the summary\n",
    "    summary = ' '.join(summary_sentences)\n",
    "    \n",
    "    # Final cleanup\n",
    "    summary = re.sub(r'\\s+', ' ', summary).strip()\n",
    "    \n",
    "    return summary"
   ],
   "outputs": [],
   "execution_count": 16
  },
  {
   "cell_type": "code",
   "id": "4d99c341ff41a3d8",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-21T00:28:02.159573Z",
     "start_time": "2024-12-21T00:28:01.598916Z"
    }
   },
   "source": [
    "# applying the extractive summarization function\n",
    "df['extractive_summary'] = df['cleaned_article'].apply(text_rank_summary)"
   ],
   "outputs": [],
   "execution_count": 17
  },
  {
   "cell_type": "code",
   "id": "c5809240e0a391f6",
   "metadata": {
    "scrolled": true,
    "ExecuteTime": {
     "end_time": "2024-12-21T00:28:02.190970Z",
     "start_time": "2024-12-21T00:28:02.170963Z"
    }
   },
   "source": [
    "# creating a dataFrame to store the extracted summaries\n",
    "ExtractiveResults_df = df[['abstract', 'extractive_summary']]\n",
    "\n",
    "# displaying the generated summaries\n",
    "print(\"\\nOriginal Abstract vs Extractive Summary:\")\n",
    "ExtractiveResults_df.head(100)"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Original Abstract vs Extractive Summary:\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "                                            abstract  \\\n",
       "0  The study investigates short-term periodicitie...   \n",
       "1  This study examines the potential to detect ci...   \n",
       "2  A new barrier penetration formula, derived fro...   \n",
       "3  The study explores marginally gravitationally ...   \n",
       "4  CDF searched for new particles decaying into j...   \n",
       "5  Observations of pre-supernova images reveal in...   \n",
       "6  This study explores single-transverse spin asy...   \n",
       "7  Kingmanâ€™s coalescent models genetic ancestri...   \n",
       "8  The study of circumstellar environments around...   \n",
       "\n",
       "                                  extractive_summary  \n",
       "0  the existence of the periodicity of about days...  \n",
       "1  we characterize sgwb by the so called stokes p...  \n",
       "2  in the present work , we derived a new barrier...  \n",
       "3  3 shows that the initial disk surface injectio...  \n",
       "4  for the mass region gev c , there are 2947 eve...  \n",
       "5  following a brief summary of sn classification...  \n",
       "6  at the same time , taking the moment of the fa...  \n",
       "7  the sequence t1 satisfies a large deviation pr...  \n",
       "8  , width529 currently , a small survey with her...  "
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>abstract</th>\n",
       "      <th>extractive_summary</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>The study investigates short-term periodicitie...</td>\n",
       "      <td>the existence of the periodicity of about days...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>This study examines the potential to detect ci...</td>\n",
       "      <td>we characterize sgwb by the so called stokes p...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>A new barrier penetration formula, derived fro...</td>\n",
       "      <td>in the present work , we derived a new barrier...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>The study explores marginally gravitationally ...</td>\n",
       "      <td>3 shows that the initial disk surface injectio...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>CDF searched for new particles decaying into j...</td>\n",
       "      <td>for the mass region gev c , there are 2947 eve...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Observations of pre-supernova images reveal in...</td>\n",
       "      <td>following a brief summary of sn classification...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>This study explores single-transverse spin asy...</td>\n",
       "      <td>at the same time , taking the moment of the fa...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Kingmanâ€™s coalescent models genetic ancestri...</td>\n",
       "      <td>the sequence t1 satisfies a large deviation pr...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>The study of circumstellar environments around...</td>\n",
       "      <td>, width529 currently , a small survey with her...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 18
  },
  {
   "cell_type": "markdown",
   "id": "4b32b3e76e6456f",
   "metadata": {},
   "source": [
    "#### Abstractive Summarization - T5 Transformer Based Model"
   ]
  },
  {
   "cell_type": "code",
   "id": "a7d451e6d75a4b2d",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-21T00:28:42.726437Z",
     "start_time": "2024-12-21T00:28:02.349494Z"
    }
   },
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Using device: {device}\")\n",
    "\n",
    "tokenizer = T5Tokenizer.from_pretrained(\"t5-base\")\n",
    "model = T5ForConditionalGeneration.from_pretrained(\"t5-base\").to(device)\n",
    "\n",
    "#  function to handle long texts with batch processing\n",
    "def generate_abstractive_summary(text, max_length=100, min_length=60, chunk_size=256):\n",
    "    # tokenizing the input text and split it into manageable chunks for faster processing\n",
    "    inputs = tokenizer(text, return_tensors='pt', truncation=True, max_length=chunk_size, padding=\"longest\")\n",
    "    input_ids = inputs['input_ids'].to(device)\n",
    "\n",
    "    summaries = []\n",
    "\n",
    "    # Processing article chunks in batches\n",
    "    batch_size = 4\n",
    "    for i in range(0, input_ids.size(0), batch_size):\n",
    "        batch_input_ids = input_ids[i:i + batch_size]\n",
    "        try:\n",
    "            outputs = model.generate(batch_input_ids, max_length=max_length, min_length=min_length, do_sample=False)\n",
    "            batch_summaries = tokenizer.batch_decode(outputs, skip_special_tokens=True)\n",
    "            summaries.extend(batch_summaries)\n",
    "        except Exception as e:\n",
    "            print(f\"Error during summarization: {e}\")\n",
    "            summaries.append(\"Error generating summary.\")\n",
    "\n",
    "    # Combining the batch summaries results to create a single summary\n",
    "    final_summary = ' '.join(summaries)\n",
    "\n",
    "    # Truncating the summary to ensure it is in the specified length range\n",
    "    final_summary_tokens = tokenizer.tokenize(final_summary)\n",
    "    if len(final_summary_tokens) > max_length:\n",
    "        final_summary = tokenizer.decode(tokenizer.encode(final_summary_tokens[:max_length]), skip_special_tokens=True)\n",
    "\n",
    "    return final_summary\n",
    "\n",
    "df['abstractive_summary'] = df['cleaned_article'].apply(lambda x: generate_abstractive_summary(x))\n",
    "\n",
    "# create a dataFrame to store the abstractive summaries\n",
    "AbstractiveResults_df = df[['abstract', 'abstractive_summary']]\n",
    "\n",
    "# displaying the generated summaries\n",
    "print(\"\\n Original Abstract vs Abstractive Summary:\")\n",
    "AbstractiveResults_df.head(100)\n"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cpu\n",
      "\n",
      " Original Abstract vs Abstractive Summary:\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "                                            abstract  \\\n",
       "0  The study investigates short-term periodicitie...   \n",
       "1  This study examines the potential to detect ci...   \n",
       "2  A new barrier penetration formula, derived fro...   \n",
       "3  The study explores marginally gravitationally ...   \n",
       "4  CDF searched for new particles decaying into j...   \n",
       "5  Observations of pre-supernova images reveal in...   \n",
       "6  This study explores single-transverse spin asy...   \n",
       "7  Kingmanâ€™s coalescent models genetic ancestri...   \n",
       "8  The study of circumstellar environments around...   \n",
       "\n",
       "                                 abstractive_summary  \n",
       "0  155day periodicity was found in data records f...  \n",
       "1  ptas are a method of searching for gravitation...  \n",
       "2  quantum tunneling is a common quantum phenomen...  \n",
       "3  . , a short lived radioisotope , was alive dur...  \n",
       "4  a general search for new particles with a narr...  \n",
       "5  cc sn progenitors have been directly detected ...  \n",
       "6  qcd in high energy hadronic scattering has bee...  \n",
       "7  a random tree arising in large population gene...  \n",
       "8  ir provides several key diagnostics for the ev...  "
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>abstract</th>\n",
       "      <th>abstractive_summary</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>The study investigates short-term periodicitie...</td>\n",
       "      <td>155day periodicity was found in data records f...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>This study examines the potential to detect ci...</td>\n",
       "      <td>ptas are a method of searching for gravitation...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>A new barrier penetration formula, derived fro...</td>\n",
       "      <td>quantum tunneling is a common quantum phenomen...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>The study explores marginally gravitationally ...</td>\n",
       "      <td>. , a short lived radioisotope , was alive dur...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>CDF searched for new particles decaying into j...</td>\n",
       "      <td>a general search for new particles with a narr...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Observations of pre-supernova images reveal in...</td>\n",
       "      <td>cc sn progenitors have been directly detected ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>This study explores single-transverse spin asy...</td>\n",
       "      <td>qcd in high energy hadronic scattering has bee...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Kingmanâ€™s coalescent models genetic ancestri...</td>\n",
       "      <td>a random tree arising in large population gene...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>The study of circumstellar environments around...</td>\n",
       "      <td>ir provides several key diagnostics for the ev...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 19
  },
  {
   "cell_type": "markdown",
   "id": "79eef6ae33a28c8d",
   "metadata": {},
   "source": [
    "## Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "id": "afd126a2-7cab-4d00-a28e-ffc7b14271e6",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-21T00:28:42.899897Z",
     "start_time": "2024-12-21T00:28:42.886889Z"
    }
   },
   "source": [
    "#functions to implement evaluation metrics\n",
    "\n",
    "# calculate avg rouge-1 score for all the summaries in the dataframe\n",
    "def compute_rouge1_avg(df, ref_col, hyp_col):\n",
    "\n",
    "    scorer = rouge_scorer.RougeScorer(['rouge1'], use_stemmer=True)\n",
    "    rouge1_scores = []\n",
    "    for ref, hyp in zip(df[ref_col], df[hyp_col]):\n",
    "        s = scorer.score(ref, hyp)\n",
    "        rouge1_scores.append(s['rouge1'].fmeasure)\n",
    "    return np.mean(rouge1_scores)\n",
    "\n",
    "\n",
    "# calculate avg rouge-2 score for all the summaries in the dataframe\n",
    "def compute_rouge2_avg(df, ref_col, hyp_col):\n",
    "\n",
    "    scorer = rouge_scorer.RougeScorer(['rouge2'], use_stemmer=True)\n",
    "    rouge2_scores = []\n",
    "    for ref, hyp in zip(df[ref_col], df[hyp_col]):\n",
    "        s = scorer.score(ref, hyp)\n",
    "        rouge2_scores.append(s['rouge2'].fmeasure)\n",
    "    return np.mean(rouge2_scores)\n",
    "\n",
    "# calculate avg BERTScore F1 for all the summaries in the dataframe\n",
    "def compute_bert_score_avg(df, ref_col, hyp_col, lang=\"en\"):\n",
    "\n",
    "    references = df[ref_col].tolist()\n",
    "    candidates = df[hyp_col].tolist()\n",
    "\n",
    "    P, R, F1 = score(candidates, references, lang=lang, verbose=False)\n",
    "    return F1.mean().item() if isinstance(F1, torch.Tensor) else np.mean(F1)\n",
    "\n",
    "# calculate avg Flesch-Kincaid Grade Level for all the summaries in the dataframe\n",
    "def compute_flesch_kincaid_avg(df, hyp_col):\n",
    "\n",
    "    fk_scores = df[hyp_col].apply(textstat.flesch_kincaid_grade)\n",
    "    return fk_scores.mean()"
   ],
   "outputs": [],
   "execution_count": 20
  },
  {
   "cell_type": "code",
   "id": "38e7369ac5cf2e64",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-21T00:29:04.770654Z",
     "start_time": "2024-12-21T00:28:43.015542Z"
    }
   },
   "source": [
    "# calculating the evaluation metrics for abstractive summaries\n",
    "abs_rouge1 = compute_rouge1_avg(AbstractiveResults_df, 'abstract', 'abstractive_summary')\n",
    "abs_rouge2 = compute_rouge2_avg(AbstractiveResults_df, 'abstract', 'abstractive_summary')\n",
    "abs_bert = compute_bert_score_avg(AbstractiveResults_df, 'abstract', 'abstractive_summary')\n",
    "abs_fk = compute_flesch_kincaid_avg(AbstractiveResults_df, 'abstractive_summary')\n",
    "\n",
    "# calculating the evaluation metrics for extractive summaries\n",
    "ext_rouge1 = compute_rouge1_avg(ExtractiveResults_df, 'abstract', 'extractive_summary')\n",
    "ext_rouge2 = compute_rouge2_avg(ExtractiveResults_df, 'abstract', 'extractive_summary')\n",
    "ext_bert = compute_bert_score_avg(ExtractiveResults_df, 'abstract', 'extractive_summary')\n",
    "ext_fk = compute_flesch_kincaid_avg(ExtractiveResults_df, 'extractive_summary')\n"
   ],
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "execution_count": 21
  },
  {
   "cell_type": "code",
   "id": "d40fa0883b16096d",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-21T00:29:04.816082Z",
     "start_time": "2024-12-21T00:29:04.790653Z"
    }
   },
   "source": [
    "# creating Evaluation_result_df to display the evaluation metrics\n",
    "Evaluation_result_df = pd.DataFrame({\n",
    "    'Method': ['Extractive', 'Abstractive'],\n",
    "    'Avg_ROUGE-1': [ext_rouge1, abs_rouge1],\n",
    "    'Avg_ROUGE-2': [ext_rouge2, abs_rouge2],\n",
    "    'Avg_BERTScore_F1': [ext_bert, abs_bert],\n",
    "    'Avg_Flesch_Kincaid': [ext_fk, abs_fk]\n",
    "})\n",
    "\n",
    "# displaying the evaluation metrics\n",
    "Evaluation_result_df"
   ],
   "outputs": [
    {
     "data": {
      "text/plain": [
       "        Method  Avg_ROUGE-1  Avg_ROUGE-2  Avg_BERTScore_F1  Avg_Flesch_Kincaid\n",
       "0   Extractive     0.294452     0.079846          0.825715           17.255556\n",
       "1  Abstractive     0.257930     0.049757          0.830853            9.344444"
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Method</th>\n",
       "      <th>Avg_ROUGE-1</th>\n",
       "      <th>Avg_ROUGE-2</th>\n",
       "      <th>Avg_BERTScore_F1</th>\n",
       "      <th>Avg_Flesch_Kincaid</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Extractive</td>\n",
       "      <td>0.294452</td>\n",
       "      <td>0.079846</td>\n",
       "      <td>0.825715</td>\n",
       "      <td>17.255556</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Abstractive</td>\n",
       "      <td>0.257930</td>\n",
       "      <td>0.049757</td>\n",
       "      <td>0.830853</td>\n",
       "      <td>9.344444</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 22
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
